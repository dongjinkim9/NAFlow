data:
  target: datasets.data_module.BaseDataModule
  params:
    # Path to training set configuration file.
    train_config: configs/datasets/sidd_train.yaml
    # Path to validation set configuration file.
    val_config: configs/datasets/sidd_val.yaml

model:
  # You can set learning rate in the following configuration file.
  config: configs/models/naflow.yaml
  # Path to the checkpoints or weights you want to resume. At the begining, 
  resume: ~

lightning:
  seed: ~
  mode: fit
  
  trainer:
    accelerator: auto # gpu # ddp
    precision: 32 # bf16-mixed # 32
    # Indices of GPUs used for training.
    devices: [0]
    # Path to save logs and checkpoints.
    default_root_dir: 
    # Max number of training steps (batches).
    max_steps: 100001
    # Validation frequency in terms of training steps.
    val_check_interval: 20000 
    check_val_every_n_epoch: ~
    log_every_n_steps: 500
  
  callbacks:
    - target: pytorch_lightning.callbacks.ModelCheckpoint
      params:
        # Frequency of saving checkpoints.
        every_n_train_steps: 10000
        save_last: True
        filename: '{epoch}-{step}'
        verbose: True

    - target: pytorch_lightning.callbacks.LearningRateMonitor
      params:
        logging_interval: 'step'

    - target: pytorch_lightning.callbacks.RichProgressBar
      params:
        leave: True

  loggers:
    - target: models.loggers.LocalImageLogger
      params:
        save_dir : ./logs/
        name: LocalImageLogger
        version: NAFlow

    # - target: models.loggers.TensorBoardLogger
    #   params:
    #     save_dir : ./logs/
    #     version: NAFlow

    # - target: models.loggers.WandbLogger
    #   params:
    #     name: NAFlow
    #     save_dir : ./logs/
    #     log_model: all # all True False
    #     entity: hyu-vilab
    #     project: NAFlow
    #     tags: []
    #     notes:
